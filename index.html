<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>PENG LI</title>
	<link rel="icon" type="image/x-icon" href="./favicon.ico"/>
	<style>
	  body {
		font-size: 18px;
	  }
	</style>
</head>

<body>
<p>
<font size="+2"><b>Peng Li (<font style="font-family:SimSun">ÊùéÈπè</font>)</b></font> <br>
</p>

<p>
E-mail: lip21 [at] m.fudan.edu.cn; pengli.ds [at] gmail.com <br>
</p>

<p>
    <h3>Biography</h3>
</p>

<p>
Currently, I am a third-year M.S. student in the NLP Group at Fudan University, advised by Prof. <a href="https://xpqiu.github.io/">Xipeng Qiu</a>.
I am now also very fortunate to work with Prof. <a href="https://www.hongyuanmei.com/">Hongyuan Mei</a> and Prof. <a href="https://home.ttic.edu/~mwalter/">Matthew R. Walter</a> at <a href="https://www.ttic.edu/">TTIC</a>.
<br>
Before coming to Fudan, I earned his B.S. degree from the School of Data Science and Engineering at East China Normal University, working with Prof. <a href="http://ybwu.org/">Yuanbin Wu</a>.
</p>

<p>
My research interest lies mainly in <b>Foundation Models for Robot Learning</b>. 
My research goal is to enable robots to autonomously interact with the real world and achieve self-evolution. 
<br>

To achieve this goal, I am currently working on the following directions:
<ul>
  <li>Enhancing the reasoning, planning, grounding, and acting capabilities of current foundation models;</li>
  <li>Designing and pretraining new foundation models for robot learning;</li>
  <li>Benchmarking the abilities of foundation models for robot learning;</li>
</ul>
</p>

<p>
<font color="red">*I am looking for a PhD position starting in Fall 2024. Here is my <a href="./Resume_PengLi_FudanNLP_Foundation_Models_for_Robot_Learning_231105.pdf">resume</a>. Please feel free to contact me!</font>
</p>

<p>
<h3>Publications (<a href="https://scholar.google.com/citations?user=4puDTtgAAAAJ&hl=en&oi=sra">Google Scholar</a>)</h3>
(*equal contribution)
</p>

<p>
<a href="https://arxiv.org/abs/2306.17840">Statler: State-Maintaining Language Models for Embodied Reasoning</a> | <a href="https://statler-lm.github.io/">Blog</a><br>
Takuma Yoneda*, Jiading Fang*, <b>Peng Li*</b>, Huanyu Zhang*, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, Matthew R. Walter<br>
<i>In submission</i><br>
</p>

<p>
<a href="https://github.com/OpenLMLab/MOSS/blob/main/README_en.md">MOSS Technical Report</a> | <a href="https://txsun1997.github.io/blogs/moss.html">Blog</a><br>
Tianxiang Sun, Xiaotian Zhang, Zhengfu He, <b>Peng Li</b>, Qinyuan Cheng, Hang Yan, Xiangyang
Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao
Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing
Huang, Xipeng Qiu<br>
<i>To appear 2023</i><br>
üëâ <abbr style="border-bottom: 1px dotted #000; ">MOSS is the first ChatGPT-like LLM in China, the first plugin-augmented LLM in China, and fully <a href="https://github.com/OpenLMLab/MOSS">open sourced</a> (11.6k+ stars).</abbr><br>
</p>

<p>
<a href="https://arxiv.org/abs/2305.05711">CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors</a> | <a href="https://github.com/artpli/CodeIE">Code</a><br>
<b>Peng Li*</b>, Tianxiang Sun*, Qiong Tang, Hang Yan, Yuanbin Wu, Xuanjing Huang, Xipeng Qiu<br>
<i>ACL 2023 </i><br> 
</p>


Last update: Nov. 2023
</body>
</html>
