<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PENG LI</title>
	<link rel="icon" type="image/x-icon" href="./favicon.ico"/>
	<style>
    body {
		font-size: 18px;
		margin: 0 auto;
		padding: 0;
		width: 80%;
    }
	</style>
</head>

<body>

<p>
<font size="+2"><b>Peng Li (<font style="font-family:SimSun">ÊùéÈπè</font>)</b></font>
</p>

<p>
E-mail: lip21 [at] m.fudan.edu.cn; pengli.ds [at] gmail.com <br>
</p>

<p>
<h3>Biography</h3>
</p>

<p>
I am currently a third-year M.S. student in the NLP Group at Fudan University, advised by Prof. <a href="https://xpqiu.github.io/">Xipeng Qiu</a>.
I am now also very fortunate to work with Prof. <a href="https://www.hongyuanmei.com/">Hongyuan Mei</a> and Prof. <a href="https://home.ttic.edu/~mwalter/">Matthew R. Walter</a> at <a href="https://www.ttic.edu/">TTIC</a>.
Before coming to Fudan, I earned my B.S. degree from the School of Data Science and Engineering at East China Normal University, working with Prof. <a href="http://ybwu.org/">Yuanbin Wu</a>.
</p>

<p>
My research interest lies mainly in <b>foundation models for robot learning</b>. 
My research goal is to build general-purpose robots to autonomously interact with the real world and achieve self-evolution.
To achieve this goal, I am 
(1) enhancing the perception, reasoning, planning, acting and learning capabilities of robots with existing CV/NLP foundation models; 
(2) designing and pretraining robotics-specific foundation models; 
(3) building new evaluation benchmarks. 
</p>

<p>
<font color="red">*I am looking for a PhD position starting in Fall 2024. Here is my <a href="./Resume_PengLi_FudanNLP_Foundation_Models_for_Robot_Learning_231125.pdf">resume</a>. Please feel free to contact me!</font><br>
</p>

<p>
<h3>Projects <font size="-1"><a href="https://scholar.google.com/citations?user=4puDTtgAAAAJ&hl=en&oi=sra">Google Scholar</a>/<a href="https://github.com/artpli">GitHub</a></font></h3>
* indicates equal contribution, and (Œ±) stands for alphabetical order of student authors.
</p>

<p>
<a href="">MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models</a><br>
Peng Ding*, Jiading Fang*, <b>Peng Li*</b>, Kangrui Wang*, Xiaochen Zhou*, Mo Yu, Jing Li, Matthew Walter, Hongyuan Mei (Œ±)<br>
In submission.<br>
[ Blog | Paper | GitHub ]
</p>

<p>
<a href="https://arxiv.org/abs/2306.17840">Statler: State-Maintaining Language Models for Embodied Reasoning</a><br>
Takuma Yoneda*, Jiading Fang*, <b>Peng Li*</b>, Huanyu Zhang*, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, Matthew R. Walter<br>
In submission.<br>
[ <a href="https://statler-lm.github.io/">Blog</a> | <a href="https://arxiv.org/abs/2306.17840">Paper</a> | GitHub ]
</p>

<p>
<a href="https://github.com/OpenLMLab/MOSS/blob/main/README_en.md">MOSS: An Open Conversational Language Model</a><br>
üåü <abbr style="border-bottom: 1px dotted #000; ">MOSS is the first ChatGPT-like LLM in China, the first plugin-augmented LLM in China, and fully open sourced with 11.7k+ stars.</abbr><br>
Tianxiang Sun, Xiaotian Zhang, Zhengfu He, <b>Peng Li</b>, Qinyuan Cheng, Hang Yan, Xiangyang
Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao
Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing
Huang, Xipeng Qiu<br>
In submission.<br>
[ <a href="https://txsun1997.github.io/blogs/moss.html">Blog</a> | Paper | <a href="https://github.com/OpenLMLab/MOSS/blob/main/README_en.md">GitHub</a> ]
</p>

<p>
<a href="https://arxiv.org/abs/2305.05711">CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors</a><br>
<b>Peng Li*</b>, Tianxiang Sun*, Qiong Tang, Hang Yan, Yuanbin Wu, Xuanjing Huang, Xipeng Qiu<br>
ACL 2023<br>
[ Blog | <a href="https://arxiv.org/abs/2305.05711">Paper</a> | <a href="https://github.com/artpli/CodeIE">GitHub</a> ]
</p>

<p>
<h3>Tech Notes</h3>
</p>

<p>
<a href="">TBC</a>
</p>

<i>Last update: Jan. 2024</i>

</body>
</html>
